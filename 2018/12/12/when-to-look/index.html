<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="图像标注,">










<meta name="description" content="论文 Knowing When to Look:A Visual Sentinel for Image Captioning">
<meta name="keywords" content="图像标注">
<meta property="og:type" content="article">
<meta property="og:title" content="Knowing When to Look:A Visual Sentinel for Image Captioning">
<meta property="og:url" content="http://yoursite.com/2018/12/12/when-to-look/index.html">
<meta property="og:site_name" content="Goodbye World">
<meta property="og:description" content="论文 Knowing When to Look:A Visual Sentinel for Image Captioning">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-01-22T01:48:38.206Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Knowing When to Look:A Visual Sentinel for Image Captioning">
<meta name="twitter:description" content="论文 Knowing When to Look:A Visual Sentinel for Image Captioning">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/12/12/when-to-look/">






  <title>Knowing When to Look:A Visual Sentinel for Image Captioning | Goodbye World</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><link href="https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css" rel="stylesheet">
<div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Goodbye World</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/12/when-to-look/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Citehtap">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/panda.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Goodbye World">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Knowing When to Look:A Visual Sentinel for Image Captioning</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-12T19:46:40+08:00">
                2018-12-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Image-Caption/" itemprop="url" rel="index">
                    <span itemprop="name">Image Caption</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>论文 <em>Knowing When to Look:A Visual Sentinel for Image Captioning</em> </p>
<a id="more"></a>
<ol>
<li><p>将图像 $I$ 输入ResNet，在ResNet的最后一个卷积层输出图像的空间特征（spatial feature），维度为 $2048 \times 7 \times 7$ ；在本文用 <script type="math/tex">A=\{a_1,\dots,a_k\},a_i\in{R^{2048}}</script> 表示the spatial feature at each of the k grid locations。同时，全局的图像特征为：</p>
<script type="math/tex; mode=display">
a^g=\frac{1}{k}\sum_{i=1}^k\alpha_i</script></li>
<li><p>为了方便建模，将图像特征通过单层感知机与ReLU，转化为新的 $d$ 维向量：</p>
<script type="math/tex; mode=display">
v_i=\text{ReLU}(W_aa_i) \\
v_g=\text{ReLU}(W_ba^g)</script><p>其中 $W_a,W_b$ 是权重参数；转化后的空间图像特征为 $V=[v_1,\dots,v_k]$ 。</p>
</li>
<li><p>将 $w_t,v^g$ 进行concat操作 $x_t=[w_t;v^g]$  后， $x_t$ 即为LSTM的输入。</p>
</li>
<li><p>在LSTM中，时刻 $t$ 的输出（hidden state）为：</p>
<script type="math/tex; mode=display">
h_t = \text{LSTM}(x_t,h_{t-1},m_{t-1})</script><p>其中， $m_{t-1}$ 为时刻 $t-1$ 的 memory cell vector</p>
</li>
<li><p>本文认为，注意力机制的一个问题在于，对于没有实义的单词（如 the, of），不应该根据图像的某一部分进行生成，而应该根据visual sentinel生成。而visual sentinel包含在decoder的memory cell的语义信息中。因此，本文认为，上下文向量的计算方式应该为：</p>
<script type="math/tex; mode=display">
\widehat{c}_t=\beta_ts_t+(1-\beta_t)c_t</script><p>其中， $\beta_t\in[0,1]$ 表示sentinel gate， $\beta_t=1$ 说明该时刻只考虑visual sentinel中的信息； $\beta_t=0$ 表示只考虑空间图像特征信息。67会给出 $\beta,c,s$ 的计算方法 </p>
</li>
<li><p>根据本文提出的空间注意力模型，上下文向量 $c_t$ 的计算方式为：</p>
<script type="math/tex; mode=display">
c_t=g(V,h_t)</script><p>其中， $g$ 是注意力函数， $V=[v_1,\dots,v_k],v_i\in{R^d}$ 是空间图像特征，其中每一项都是代表了图像一部分的 $d$ 维的向量； $h_t$ 是RNN时刻 $t$ 的hidden state。</p>
<p>对给定的 $V\in[v_1,\dots,v_k],v_i\in{R^d}$ 以及LSTM的hidden state $h_t\in{R^d}$ ，将它们输入一个带softmax的单层神经网络，来生成一个在 $k$ 个区域上的注意力分布：</p>
<script type="math/tex; mode=display">
z_t=w_h^T\text{tanh}(W_vV+(W_gh_t)\mathbb{1}^T) \\
\alpha_t=\text{softmax}(z_t)</script><p>其中， $1\in{R^k}$ 为所有元素都是1的向量， $W_v,W_g\in{R^{k\times{d}}}$ 是需要学习的参数， $\alpha\in{R^k}$ 是在特征 $V$ 上的注意力权重。基于这种注意力分布，可以计算上下文变量：</p>
<script type="math/tex; mode=display">
c_t=\sum_{i=1}^k\alpha_{ti}v_{ti}</script></li>
<li><p>扩展LSTM，得到visual sentinel：</p>
<script type="math/tex; mode=display">
g_t=\sigma(W_xx_t+W_hh_{t-1}) \\
s_t=g_t\odot\tanh(m_t)</script><p>其中， $W_x,W_h$ 是需要学习的参数，$x_t$ 是LSTM的输入， $\odot$ 是矩阵的点积， $\sigma$ 是logistic sigmoid。</p>
</li>
<li><p>为了计算 $\beta_t$ ，本文对空间注意力 $z_t$ 进行了修改：在 $z_t$ 后添加一个矩阵，该矩阵代表了模型在visual sentinel上的注意力：</p>
<script type="math/tex; mode=display">
\widehat{\alpha}_t=\text{softmax}([z_t;w_h^T\tanh(W_ss_t+(W_gh_t))])</script><p>其中， $W_g,W_s$ 是权重参数； $W_g$ 和计算 $z_t$ 时的 $W_g$ 相同。</p>
<p>由于 $\widehat{\alpha}_t\in{R^{k+1}}$ 是在空间图像特征和visual sentinel上的注意力分布，因此可以得到：</p>
<script type="math/tex; mode=display">
\beta_t=\alpha_t[k+1]</script></li>
<li><p>最后，时间 $t$ 时，单词表中每个可能的单词的概率可计算为：</p>
<script type="math/tex; mode=display">
p_t=\text{softmax}(W_p(\widehat{c}_t+h_t))</script><p>其中， $W_p$ 是训练参数。</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pack_padded_sequence</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AttentiveCNN</span><span class="params">( nn.Module )</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">( self, embed_size, hidden_size )</span>:</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span><span class="params">( self )</span>:</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">( self, images )</span>:</span></span><br><span class="line">        <span class="keyword">return</span> V, v_g</span><br><span class="line"></span><br><span class="line"><span class="comment"># Attention Block for C_hat calculation</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Atten</span><span class="params">( nn.Module )</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">( self, hidden_size )</span>:</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span><span class="params">( self )</span>:</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">( self, V, h_t, s_t )</span>:</span></span><br><span class="line">        <span class="keyword">return</span> c_hat_t, alpha_t, beta_t</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sentinel BLock    </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sentinel</span><span class="params">( nn.Module )</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">( self, input_size, hidden_size )</span>:</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span><span class="params">( self )</span>:</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">( self, x_t, h_t_1, cell_t )</span>:</span></span><br><span class="line">        <span class="keyword">return</span> s_t</span><br><span class="line"></span><br><span class="line"><span class="comment"># Adaptive Attention Block: C_t, Spatial Attention Weights, Sentinel embedding    </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdaptiveBlock</span><span class="params">( nn.Module )</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">( self, embed_size, hidden_size, vocab_size )</span>:</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span><span class="params">( self )</span>:</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">( self, x, hiddens, cells, V )</span>:</span></span><br><span class="line">        <span class="keyword">return</span> scores, atten_weights, beta</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_hidden</span><span class="params">( self, bsz )</span>:</span></span><br><span class="line">        <span class="keyword">return</span> ( Variable( weight.new( <span class="number">1</span> , bsz, self.hidden_size ).zero_() ),</span><br><span class="line">                    Variable( weight.new( <span class="number">1</span>,  bsz, self.hidden_size ).zero_() ) ) </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># Caption Decoder</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span><span class="params">( nn.Module )</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">( self, embed_size, vocab_size, hidden_size )</span>:</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">( self, V, v_g , captions, states=None )</span>:</span></span><br><span class="line">        <span class="keyword">return</span> scores, states, atten_weights, beta</span><br><span class="line">    </span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"><span class="comment"># Whole Architecture with Image Encoder and Caption decoder        </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder2Decoder</span><span class="params">( nn.Module )</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">( self, embed_size, vocab_size, hidden_size )</span>:</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">( self, images, captions, lengths )</span>:</span></span><br><span class="line">        <span class="keyword">return</span> packed_scores</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Caption generator</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sampler</span><span class="params">( self, images, max_len=<span class="number">20</span> )</span>:</span></span><br><span class="line">        <span class="keyword">return</span> sampled_ids, attention, Beta</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">from config import Config</span><br><span class="line">from torch import nn</span><br><span class="line">import os</span><br><span class="line">import torch</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">import pickle</span><br><span class="line">from dataset_loader import get_loader</span><br><span class="line">from nic import Encoder, Decoder</span><br><span class="line">from torch.nn.utils.rnn import pack_padded_sequence</span><br><span class="line">import numpy as np</span><br><span class="line">from vocabulary import Vocabulary</span><br><span class="line">config = Config()</span><br><span class="line">device = torch.device(&apos;cuda&apos; if torch.cuda.is_available() else &apos;cpu&apos;)</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    if not os.path.exists(config.model_path):</span><br><span class="line">        os.makedirs(config.model_path)</span><br><span class="line"></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.RandomCrop(config.crop_size),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((0.485, 0.456, 0.406),</span><br><span class="line">                             (0.229, 0.224, 0.225))])</span><br><span class="line"></span><br><span class="line">    with open(config.vocab_path, &apos;rb&apos;) as v:</span><br><span class="line">        vocab = pickle.load(v)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    loader = get_loader(config.image_resized_path, config.split_train_path, vocab,</span><br><span class="line">                                       transform, config.batch_size,</span><br><span class="line">                                       shuffle=True, num_workers=config.num_workers)</span><br><span class="line"></span><br><span class="line">    encoder = Encoder(config.embed_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    decoder = Decoder(len(vocab), config.embed_size, config.hidden_size)</span><br><span class="line"></span><br><span class="line">    # Loss and optimizer</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    params = list(decoder.parameters()) + list(encoder.linear.parameters()) + list(encoder.bn.parameters())</span><br><span class="line">    optimizer = torch.optim.Adam(params, lr=config.learning_rate, betas=(config.alpha, config.beta))</span><br><span class="line"></span><br><span class="line">    # Train the models</span><br><span class="line">    total_step = len(loader)</span><br><span class="line">    for epoch in range(config.num_epochs):</span><br><span class="line">        for i, (images, captions, lengths, _, _) in enumerate(loader):</span><br><span class="line"></span><br><span class="line">            # Set mini-batch dataset</span><br><span class="line">            # images = images.to(device)</span><br><span class="line">            # captions = captions.to(device)</span><br><span class="line">            targets = pack_padded_sequence(captions[:, 1:], lengths, batch_first=True)[0]</span><br><span class="line"></span><br><span class="line">            # Forward, backward and optimize</span><br><span class="line">            features = encoder(images)</span><br><span class="line">            outputs = decoder(features, captions, lengths)</span><br><span class="line">            loss = criterion(outputs, targets)</span><br><span class="line">            decoder.zero_grad()</span><br><span class="line">            encoder.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            # Print log info</span><br><span class="line">            if i % config.log_step == 0:</span><br><span class="line">                print(&apos;Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], Loss: &#123;:.4f&#125;, Perplexity: &#123;:5.4f&#125;&apos;</span><br><span class="line">                      .format(epoch, config.num_epochs, i, total_step, loss.item(), np.exp(loss.item())))</span><br><span class="line"></span><br><span class="line">                # Save the model checkpoints</span><br><span class="line">            if (i + 1) % config.save_step == 0:</span><br><span class="line">                torch.save(decoder.state_dict(), os.path.join(</span><br><span class="line">                    config.model_path, &apos;decoder-&#123;&#125;-&#123;&#125;.ckpt&apos;.format(epoch + 1, i + 1)))</span><br><span class="line">                torch.save(encoder.state_dict(), os.path.join(</span><br><span class="line">                    config.model_path, &apos;encoder-&#123;&#125;-&#123;&#125;.ckpt&apos;.format(epoch + 1, i + 1)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/图像标注/" rel="tag"># 图像标注</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/12/03/show-attend-tell/" rel="next" title="show_attend_tell">
                <i class="fa fa-chevron-left"></i> show_attend_tell
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/01/20/how-to-read/" rel="prev" title="实用性阅读指南">
                实用性阅读指南 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/panda.jpg" alt="Citehtap">
            
              <p class="site-author-name" itemprop="name">Citehtap</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Citehtap</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
